{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Différentes approches de sélection des fonctionnalités"
      ],
      "metadata": {
        "id": "TO6JDecz7S72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Méthodes de sélection de fonctionnalités non supervisées"
      ],
      "metadata": {
        "id": "x9WLQ1i07U8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le transformateur `sklearn.feature_selection.VarianceThreshold` supprimera par défaut toutes les fonctionnalités à variance nulle. On peut également passer un seuil en argument pour lui faire supprimer les entités dont la variance est inférieure au seuil."
      ],
      "metadata": {
        "id": "m8m1yYRFQfGB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozZn9QyH0-yb"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "sel = VarianceThreshold(threshold=0.05)\n",
        "X_selection = sel.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Afin de supprimer les colonnes avec des valeurs manquantes, la méthode `.dropna(axis=1)` de pandas peut être utilisée sur le bloc de données."
      ],
      "metadata": {
        "id": "m1Ge_Eg3RBom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_selection = X.dropna(axis=1)"
      ],
      "metadata": {
        "id": "or6uB5UK7dmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour supprimer les entités à forte multicolinéarité, nous devons d’abord la mesurer. Une mesure de multicolinéarité populaire est le Variance Inflation Factor ou VIF. Il est implémenté dans le package statsmodels."
      ],
      "metadata": {
        "id": "pq6yind-RI9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "vif_scores = [variance_inflation_factor(X.values, feature)for feature in range(len(X.columns))]"
      ],
      "metadata": {
        "id": "-p5gUX0rRJY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Par convention, les colonnes avec un VIF supérieur à 10 sont considérées comme souffrant de multicolinéarité, mais un autre seuil peut être choisi s'il paraît plus raisonnable."
      ],
      "metadata": {
        "id": "-6OMfmgZSXQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Méthodes de sélection des fonctionnalités du wrapper(supervivisé):"
      ],
      "metadata": {
        "id": "hdW0WjFcUmVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chaque nouveau sous-ensemble est utilisé pour entraîner un modèle dont les performances sont ensuite évaluées sur un ensemble d'exclusion. Le sous-ensemble de fonctionnalités qui donne les meilleures performances du modèle est sélectionné."
      ],
      "metadata": {
        "id": "_1AXkZTNUmzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mais en même temps, elle présente une limite. Les méthodes wrapper sont susceptibles de s'adapter au type de modèle, et les sous-ensembles de fonctionnalités qu'elles produisent pourraient ne pas se généraliser si l'on souhaite les essayer avec un modèle différent.\n",
        "\n",
        "Un autre inconvénient important des méthodes wrapper réside dans leurs besoins de calcul importants. Ils nécessitent la formation d’un grand nombre de modèles, ce qui peut nécessiter du temps et de la puissance de calcul."
      ],
      "metadata": {
        "id": "otvCSoB-VE7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Les méthodes d'emballage populaires incluent :\n",
        "\n",
        "Sélection descendante , dans laquelle nous commençons par un modèle complet comprenant toutes les fonctionnalités disponibles. Dans les itérations suivantes, nous supprimons une fonctionnalité à la fois, toujours celle qui génère le gain le plus important dans une métrique de performances de modèle, jusqu'à ce que nous atteignions le nombre souhaité de fonctionnalités.\n",
        "La sélection directe , qui fonctionne dans le sens inverse : on part d'un modèle nul avec zéro fonctionnalité et on les ajoute goulûment une à la fois pour maximiser les performances du modèle.\n",
        "\n",
        "Recursive Feature Elimination , ou RFE, dont l'esprit est similaire à la sélection arrière. Il commence également par un modèle complet et élimine de manière itérative les fonctionnalités une par une. La différence réside dans la manière dont les fonctionnalités à supprimer sont choisies. Au lieu de s'appuyer sur une mesure de performance du modèle issue d'un ensemble d'éléments retenus, RFE prend sa décision en fonction de l'importance des fonctionnalités extraites du modèle. Il peut s'agir de la pondération des caractéristiques dans les modèles linéaires, de la diminution des impuretés dans les modèles arborescents ou de l'importance de la permutation (qui s'applique à tout type de modèle).*"
      ],
      "metadata": {
        "id": "dK21pMstVHQk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Méthodes d'emballage en pratique"
      ],
      "metadata": {
        "id": "Fd7dX7YtWpRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La sélection de fonctionnalités en arrière et en avant peut être implémentée avec le transformateur SequentialFeatureSelector. Par exemple, afin d'utiliser le classificateur k-Nearest-Neighbour comme modèle de notation dans la sélection directe, nous pourrions utiliser l'extrait de code suivant :"
      ],
      "metadata": {
        "id": "O5MaZtD5YD8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "sfs = SequentialFeatureSelector(knn, n_features_to_select=3, direction=”forward”)\n",
        "sfs.fit(X, y)\n",
        "X_selection = sfs.transform(X)"
      ],
      "metadata": {
        "id": "YB9PYytUYJJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'élimination récursive des fonctionnalités est implémentée de manière très similaire. Voici un extrait implémentant RFE basé sur l'importance des fonctionnalités d'un classificateur de vecteurs de support."
      ],
      "metadata": {
        "id": "EiXrorzMYPjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "svc = SVC(kernel=\"linear\")\n",
        "rfe = RFE(svc, n_features_to_select=3)\n",
        "rfe.fit(X, y)\n",
        "X_selection = rfe.transform(X)"
      ],
      "metadata": {
        "id": "yykieWg2YUvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Filtrer les méthodes de sélection des fonctionnalités(supervisés)"
      ],
      "metadata": {
        "id": "1aCFWvjWaLQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un autre membre de la famille supervisée est celui des méthodes de filtrage. Ils peuvent être considérés comme une alternative plus simple et plus rapide aux wrappers. Afin d'évaluer l'utilité de chaque fonctionnalité, ils analysent simplement sa relation statistique avec la cible du modèle, en utilisant des mesures telles que la corrélation ou l'information mutuelle comme indicateur de performance du modèle.\n",
        "\n",
        "Non seulement les méthodes de filtrage sont plus rapides que les wrappers, mais elles sont également plus générales car elles sont indépendantes du modèle ; ils ne seront pas suradaptés à un algorithme particulier. Ils sont également assez faciles à interpréter : une caractéristique est ignorée si elle n’a aucune relation statistique avec la cible.\n",
        "\n",
        "D’un autre côté, les méthodes de filtrage présentent cependant un inconvénient majeur. Ils examinent chaque fonctionnalité isolément, évaluant sa relation avec la cible. Cela les rend enclins à ignorer les fonctionnalités utiles qui sont en elles-mêmes de faibles prédicteurs de la cible, mais qui ajoutent beaucoup de valeur au modèle lorsqu'elles sont combinées avec d'autres fonctionnalités."
      ],
      "metadata": {
        "id": "WHOf5mMGaP_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Méthodes de filtrage en pratique\n"
      ],
      "metadata": {
        "id": "6GAYgMXfbQ7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voyons maintenant l'implémentation de différentes méthodes de filtrage. Ceux-ci auront besoin de plus de code de colle à implémenter. Tout d’abord, nous devons calculer la mesure de corrélation souhaitée entre chaque caractéristique et la cible. Ensuite, nous trierions toutes les fonctionnalités en fonction des résultats et conserverions le nombre souhaité (top-K ou top-30%) de celles ayant la corrélation la plus forte. Heureusement, scikit-learn fournit quelques utilitaires pour vous aider dans cette entreprise.\n",
        "\n",
        "Pour conserver les 2 principales fonctionnalités présentant la corrélation de Pearson la plus forte avec la cible, nous pouvons exécuter :"
      ],
      "metadata": {
        "id": "Kynvcv72bOcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import r_regression, SelectKBest\n",
        "\n",
        "X_selection = SelectKBest(r_regression, k=2).fit_transform(X, y)"
      ],
      "metadata": {
        "id": "-VBaIJtqaPp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De même, pour conserver les 30 % de fonctionnalités les plus performantes, nous exécuterions :"
      ],
      "metadata": {
        "id": "yq-JL2hAdmkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\tfrom sklearn.feature_selection import r_regression, SelectPercentile\n",
        "\n",
        "\tX_selection = SelectPercentile(r_regression, percentile=30).fit_transform(X, y)"
      ],
      "metadata": {
        "id": "J4_0OYsNdnT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les méthodes `SelectKBest` et `SelectPercentile` fonctionneront également avec des mesures de corrélation personnalisées ou non scikit-learn, à condition qu'elles renvoient un vecteur de longueur égale au nombre de fonctionnalités, avec un nombre pour chaque fonctionnalité indiquant la force de son association avec la cible. Voyons maintenant comment calculer toutes les différentes mesures de corrélation (nous discuterons de ce qu'elles signifient et quand choisir laquelle plus tard).\n",
        "\n",
        "Spearman's Rho, Kendall Tau et la corrélation point-bisériale sont tous disponibles dans le package scipy. Voici comment obtenir leurs valeurs pour chaque fonctionnalité dans X."
      ],
      "metadata": {
        "id": "fy9au8e2duZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "rho_corr = [stats.spearmanr(X[:, f], y).correlation for f in range(X.shape[1])]\n",
        "\n",
        "tau_corr = [stats.kendalltau(X[:, f], y).correlation for f in range(X.shape[1])]\n",
        "\n",
        "pbs_corr = [stats.pointbiserialr(X[:, f], y).correlation for f in range(X.shape[1])]"
      ],
      "metadata": {
        "id": "EjvpAPtjd1Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le chi carré, les informations mutuelles et le score ANOVA F sont tous dans scikit-learn. Notez que les informations mutuelles ont une implémentation distincte, selon que la cible est nominale ou non."
      ],
      "metadata": {
        "id": "-LobFYBAd13h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "chi2_corr = chi2(X, y)[0]\n",
        "f_corr = f_classif(X, y)[0]\n",
        "mi_reg_corr = mutual_info_regression(X, y)\n",
        "mi_class_corr = mutual_info_classif(X, y)"
      ],
      "metadata": {
        "id": "7H-v6OQHd25D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cramer's V peut être obtenu à partir d'une version récente de Scipy (1.7.0 ou supérieure)."
      ],
      "metadata": {
        "id": "WQKKBPxOd9eT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats.contingency import association\n",
        "\n",
        "v_corr = [association(np.hstack([X[:, f].reshape(-1, 1), y.reshape(-1, 1)]), method=\"cramer\") for f in range(X.shape[1])]\n"
      ],
      "metadata": {
        "id": "KHI5rmiEd-Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mesurer les corrélations pour différents types de données\n",
        "Lorsque les deux variables que nous comparons, c'est-à-dire la caractéristique et la cible, sont toutes deux soit un intervalle, soit un rapport, nous sommes autorisés à utiliser la mesure de corrélation la plus populaire : la corrélation de Pearson, également connue sous le nom de r de Pearson .\n",
        "\n",
        "C’est formidable, mais la corrélation de Pearson présente deux inconvénients : elle suppose que les deux variables sont normalement distribuées et elle ne mesure que la corrélation linéaire entre elles. Lorsque la corrélation est non linéaire, le r de Pearson ne la détectera pas, même si elle est très forte.\n",
        "\n",
        "Vous avez peut-être entendu parler de l' ensemble de données Datasaurus compilé par Alberto Cairo. Il se compose de 13 paires de variables, chacune présentant la même très faible corrélation de Pearson de -0,06. Comme cela devient rapidement évident une fois que nous les avons tracés, les paires sont en fait assez fortement corrélées, bien que de manière non linéaire."
      ],
      "metadata": {
        "id": "jxNRJmGVCrmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lorsque des relations non linéaires sont attendues, une des alternatives à la corrélation de Pearson doit être prise en compte. Les deux plus populaires sont :\n",
        "\n",
        "Corrélation des rangs de Spearman (Spearman's Rho),\n",
        "La corrélation de rang de Spearman est une alternative à la corrélation de Pearson pour les variables rapport/intervalle. Comme son nom l'indique, il examine uniquement les valeurs de classement, c'est-à-dire qu'il compare les deux variables en termes de positions relatives de points de données particuliers au sein des variables. Il est capable de capturer des relations non linéaires, mais il n'y a rien de gratuit : nous perdons certaines informations en ne considérant que le classement au lieu des points de données exacts.\n",
        "\n",
        "Corrélation des rangs de Kendall (Kendall Tau).\n",
        "Une autre mesure de corrélation basée sur les classements est la corrélation des classements de Kendall. Elle est similaire dans son esprit à la corrélation de Spearman mais formulée d'une manière légèrement différente (les calculs de Kendall sont basés sur des paires de valeurs concordantes et discordantes, par opposition aux calculs de Spearman basés sur des écarts). Kendall est souvent considéré comme plus robuste face aux valeurs aberrantes des données.\n",
        "\n",
        "Si au moins une des variables comparées est de type ordinal, la corrélation de rang de Spearman ou de Kendall est la voie à suivre. Étant donné que les données ordinales contiennent uniquement des informations sur les rangs, elles correspondent toutes deux parfaitement, tandis que la corrélation linéaire de Pearson est de peu d'utilité.\n",
        "\n",
        "Un autre scénario est celui où les deux variables sont nominales. Dans ce cas, nous pouvons choisir parmi plusieurs mesures de corrélation différentes :\n",
        "\n",
        "Le V de Cramer , qui capture l'association entre les deux variables en un nombre allant de zéro (pas d'association) à un (une variable complètement déterminée par l'autre).\n",
        "\n",
        "Statistique du chi carré couramment utilisée pour tester la dépendance entre deux variables. Le manque de dépendance suggère que la fonctionnalité particulière n’est pas utile.\n",
        "\n",
        "Information mutuelle : mesure de dépendance mutuelle entre deux variables qui cherche à quantifier la quantité d'informations que l'on peut extraire d'une variable sur l'autre."
      ],
      "metadata": {
        "id": "xPhKWef0P574"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans de tels cas, les deux mesures de corrélation les plus utilisées sont :\n",
        "\n",
        "ANOVA F-score , un équivalent du chi carré pour le cas où l'une des variables est continue tandis que l'autre est nominale,\n",
        "\n",
        "Corrélation point-bisériale, mesure de corrélation spécialement conçue pour évaluer la relation entre une variable binaire et une variable continue.\n",
        "\n",
        "Encore une fois, il n’existe pas de solution miracle. Le score F ne capture que les relations linéaires, tandis que la corrélation point-bisérielle émet une forte hypothèse de normalité qui pourrait ne pas être vérifiée dans la pratique, ce qui compromettrait ses résultats."
      ],
      "metadata": {
        "id": "eCwQw6WFQExP"
      }
    }
  ]
}